{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu02aQKwSoVr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sklearn.linear_model\n",
        "import sklearn.pipeline\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data_reviews'\n",
        "x_train_df = pd.read_csv('x_train.csv')\n",
        "y_train_df = pd.read_csv('y_train.csv')\n",
        "\n",
        "N, n_cols = x_train_df.shape\n",
        "print(\"Shape of x_train_df: (%d, %d)\" % (N,n_cols))\n",
        "print(\"Shape of y_train_df: %s\" % str(y_train_df.shape))\n",
        "\n",
        "# Print out the first five rows and last five rows\n",
        "tr_text_list = x_train_df['text'].values.tolist()\n",
        "rows = np.arange(0, 5)\n",
        "for row_id in rows:\n",
        "    text = tr_text_list[row_id]\n",
        "    print(\"row %5d | y = %d | %s\" % (row_id, y_train_df.values[row_id,0], text))\n",
        "\n",
        "print(\"...\")\n",
        "rows = np.arange(N - 5, N)\n",
        "for row_id in rows:\n",
        "    text = tr_text_list[row_id]\n",
        "    print(\"row %5d | y = %d | %s\" % (row_id, y_train_df.values[row_id,0], text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg62Y_3iS3Xx",
        "outputId": "9b803f42-212e-4f30-efd2-5fe185aee659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train_df: (2400, 2)\n",
            "Shape of y_train_df: (2400, 1)\n",
            "row     0 | y = 0 | Oh and I forgot to also mention the weird color effect it has on your phone.\n",
            "row     1 | y = 0 | THAT one didn't work either.\n",
            "row     2 | y = 0 | Waste of 13 bucks.\n",
            "row     3 | y = 0 | Product is useless, since it does not have enough charging current to charge the 2 cellphones I was planning to use it with.\n",
            "row     4 | y = 0 | None of the three sizes they sent with the headset would stay in my ears.\n",
            "...\n",
            "row  2395 | y = 1 | The sweet potato fries were very good and seasoned well.\n",
            "row  2396 | y = 1 | I could eat their bruschetta all day it is devine.\n",
            "row  2397 | y = 1 | Ambience is perfect.\n",
            "row  2398 | y = 1 | We ordered the duck rare and it was pink and tender on the inside with a nice char on the outside.\n",
            "row  2399 | y = 1 | Service was good and the company was better!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_df"
      ],
      "metadata": {
        "id": "XzoWQOq4THbU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b9693209-3c14-4ae1-ffc8-d23c683c191e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     website_name                                               text\n",
              "0          amazon  Oh and I forgot to also mention the weird colo...\n",
              "1          amazon                       THAT one didn't work either.\n",
              "2          amazon                                 Waste of 13 bucks.\n",
              "3          amazon  Product is useless, since it does not have eno...\n",
              "4          amazon  None of the three sizes they sent with the hea...\n",
              "...           ...                                                ...\n",
              "2395         yelp  The sweet potato fries were very good and seas...\n",
              "2396         yelp  I could eat their bruschetta all day it is dev...\n",
              "2397         yelp                               Ambience is perfect.\n",
              "2398         yelp  We ordered the duck rare and it was pink and t...\n",
              "2399         yelp       Service was good and the company was better!\n",
              "\n",
              "[2400 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09d46e4e-621a-4078-ae60-a807340fe7e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>website_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>amazon</td>\n",
              "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amazon</td>\n",
              "      <td>THAT one didn't work either.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazon</td>\n",
              "      <td>Waste of 13 bucks.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amazon</td>\n",
              "      <td>Product is useless, since it does not have eno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>amazon</td>\n",
              "      <td>None of the three sizes they sent with the hea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2395</th>\n",
              "      <td>yelp</td>\n",
              "      <td>The sweet potato fries were very good and seas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2396</th>\n",
              "      <td>yelp</td>\n",
              "      <td>I could eat their bruschetta all day it is dev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2397</th>\n",
              "      <td>yelp</td>\n",
              "      <td>Ambience is perfect.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>yelp</td>\n",
              "      <td>We ordered the duck rare and it was pink and t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2399</th>\n",
              "      <td>yelp</td>\n",
              "      <td>Service was good and the company was better!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2400 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09d46e4e-621a-4078-ae60-a807340fe7e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09d46e4e-621a-4078-ae60-a807340fe7e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09d46e4e-621a-4078-ae60-a807340fe7e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b87952f-1c08-4445-a2d9-6e6ed6a9e6e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b87952f-1c08-4445-a2d9-6e6ed6a9e6e9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b87952f-1c08-4445-a2d9-6e6ed6a9e6e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_np = x_train_df['text'].to_numpy()\n",
        "print(x_train_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldWZJOZdTvaE",
        "outputId": "29b1c379-b785-4940-b721-ca35dd937fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Oh and I forgot to also mention the weird color effect it has on your phone.'\n",
            " \"THAT one didn't work either.\" 'Waste of 13 bucks.' ...\n",
            " 'Ambience is perfect.'\n",
            " 'We ordered the duck rare and it was pink and tender on the inside with a nice char on the outside.'\n",
            " 'Service was good and the company was better!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oif-cH8tTyga",
        "outputId": "0b00efcc-e8cd-426a-dcc0-771c8686654f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2400"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def tokenize_text(raw_text):\n",
        "    ''' Transform a plain-text string into a list of tokens\n",
        "\n",
        "    We assume that *whitespace* divides tokens.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    raw_text : string\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list_of_tokens : list of strings\n",
        "        Each element is one token in the provided text\n",
        "    '''\n",
        "    list_of_tokens = raw_text.split() # split method divides on whitespace by default\n",
        "    for pp in range(len(list_of_tokens)):\n",
        "        cur_token = list_of_tokens[pp]\n",
        "        # Remove punctuation\n",
        "        # # ['?', '!', '&', '+', '_', '.', ',', '\"', '/', '(', ')', '-']\n",
        "        for punc in set(string.punctuation):\n",
        "            cur_token = cur_token.replace(punc, \"\")\n",
        "\n",
        "        if cur_token and not cur_token.isnumeric():\n",
        "          # Turn to lower case\n",
        "          clean_token = cur_token.lower()\n",
        "          # Replace the cleaned token into the original list\n",
        "          list_of_tokens[pp] = clean_token\n",
        "    return list_of_tokens"
      ],
      "metadata": {
        "id": "shGbgnYJTyi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8379ad-bb9e-405c-c8e0-672accba3cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect frequency of all relevant words (all non-stopwords)\n",
        "word_freq = dict()\n",
        "for text in x_train_np:\n",
        "  tokens = tokenize_text(text)\n",
        "  for token in tokens:\n",
        "    if len(token) > 1 and token not in stop_words:\n",
        "      if token not in word_freq:\n",
        "        word_freq[token] = 1\n",
        "      else:\n",
        "        word_freq[token] += 1\n",
        "\n",
        "sorted_word_freq = list(sorted(word_freq, key=word_freq.get, reverse=True))\n",
        "for w in sorted_word_freq[:10]:\n",
        "  print(\"%5d %s\" % (word_freq[w], w))"
      ],
      "metadata": {
        "id": "M7yriM9mTykz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587515b1-7930-4c09-ffb4-3f3946ae84dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  183 good\n",
            "  162 great\n",
            "  141 movie\n",
            "  137 phone\n",
            "  122 film\n",
            "  112 one\n",
            "  100 place\n",
            "   99 food\n",
            "   95 like\n",
            "   85 service\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_list = [w for w in sorted_word_freq if word_freq[w] >= 4]\n",
        "vocab_dict = dict()\n",
        "for id, word in enumerate(vocab_list):\n",
        "  vocab_dict[word] = id"
      ],
      "metadata": {
        "id": "C0Y1zg6nTym1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_text_into_feature_vector(text, vocab_dict):\n",
        "    ''' Produce count feature vector for provided text\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    text : string\n",
        "        A string of raw text, representing a single 'review'\n",
        "    vocab_dict : dict with string keys\n",
        "        If token is in vocabulary, will exist as key in the dict\n",
        "        If token is not in vocabulary, will not be in the dict\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    count_V : 1D numpy array, shape (V,) = (n_vocab,)\n",
        "        Count vector, indicating how often each vocab word\n",
        "        appears in the provided text string\n",
        "    '''\n",
        "    V = len(vocab_dict.keys())\n",
        "    count_V = np.zeros(V)\n",
        "    for tok in tokenize_text(text):\n",
        "        if tok in vocab_dict:\n",
        "            vv = vocab_dict[tok]\n",
        "            count_V[vv] += 1\n",
        "    return count_V"
      ],
      "metadata": {
        "id": "ecQCUJxHTyqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test: transform_text_into_feature_vector(\"dinosaur nonsense\", vocab_dict)"
      ],
      "metadata": {
        "id": "Ld7Plpbfb5ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(x_train_np)\n",
        "V = len(vocab_list)\n",
        "\n",
        "y_tr_N = y_train_df['is_positive_sentiment'].to_numpy()\n",
        "x_tr_NV = np.zeros((N, V))\n",
        "\n",
        "for idx, text in enumerate(x_train_np):\n",
        "  x_tr_NV[idx] = transform_text_into_feature_vector(text, vocab_dict)\n",
        "\n",
        "print(x_tr_NV.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1dsmy_9miCY",
        "outputId": "7992f349-51b3-4a25-b0a3-d1473efe7731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2400, 770)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(C=10000.0, max_iter=100)\n",
        "clf.fit(x_tr_NV, y_tr_N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "3rUwl9hvcKfw",
        "outputId": "f9aa7719-8899-4f61-a91e-088da348f1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000.0)"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10000.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10000.0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_tr_N = clf.predict(x_tr_NV)\n",
        "acc = np.mean(y_tr_N == yhat_tr_N)\n",
        "\n",
        "print(\"Training accuracy: %.3f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW62ot5Eca_u",
        "outputId": "758cf8ae-1396-4993-ab04-9a5c69c683fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pd.read_csv('x_test.csv')\n",
        "x_test_np = x_test['text'].to_numpy()\n",
        "\n",
        "for line in x_test_np:\n",
        "  x_V = transform_text_into_feature_vector(line, vocab_dict)\n",
        "  print(clf.predict(x_V.reshape((1, V))), line)"
      ],
      "metadata": {
        "id": "YmWFhhIec_P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## cross_validation"
      ],
      "metadata": {
        "id": "JGpBO27sX0Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "fold_sizes = [3, 5, 10, 15, 20, 25, 30]  # The last one is for LOOCV\n",
        "C_values = np.logspace(11, 16, 10)\n",
        "print(C_values)\n",
        "\n",
        "best_score = 0\n",
        "best_C = None\n",
        "\n",
        "for C in C_values:\n",
        "    # Compute cross-validation score\n",
        "    clf_lr = LogisticRegression(C=C, max_iter=100, solver='lbfgs')\n",
        "    scores = cross_val_score(clf_lr.fit(x_tr_NV, y_tr_N), x_tr_NV, y_tr_N, cv=5, scoring='accuracy')\n",
        "    mean_score = scores.mean()\n",
        "\n",
        "    if mean_score > best_score:\n",
        "      best_score = mean_score\n",
        "      best_C = C\n",
        "\n",
        "    # print(f\"Mean accuracy using {k}-fold cross-validation: {mean_score:.4f}\")\n",
        "\n",
        "print(\"C: \", best_C)\n",
        "# C:  0.4832930238571752 for 25 folds"
      ],
      "metadata": {
        "id": "qTe5D8MEX0Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(C=359381366380.4626, max_iter=1000)\n",
        "clf.fit(x_tr_NV, y_tr_N)\n",
        "\n",
        "yhat_tr_N = clf.predict(x_tr_NV)\n",
        "acc = np.mean(y_tr_N == yhat_tr_N)\n",
        "\n",
        "print(\"Training accuracy: %.3f\" % acc)"
      ],
      "metadata": {
        "id": "oxfB_SC8X0cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pd.read_csv('x_test.csv')\n",
        "x_test_np = x_test['text'].to_numpy()\n",
        "\n",
        "for line in x_test_np:\n",
        "  x_V = transform_text_into_feature_vector(line, vocab_dict)\n",
        "  print(clf.predict(x_V.reshape((1, V))), line)"
      ],
      "metadata": {
        "id": "DZfNhWWXFRwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(set(stopwords.words('english')))\n",
        "\n",
        "data = pd.read_csv('x_train.csv')\n",
        "dataset = data['text'].to_numpy()\n",
        "vectorizer = CountVectorizer(stop_words=stop_words, min_df=1, max_df=1.0, ngram_range=(1,1))\n",
        "X = vectorizer.fit_transform(dataset)\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtwccdzDTLvQ",
        "outputId": "6b22c8a9-129c-440a-b9f0-6b51bae2e6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Solution to Part 1\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import PredefinedSplit, GridSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(set(stopwords.words('english')))\n",
        "\n",
        "x_train_df = pd.read_csv('x_train.csv')\n",
        "y_train_df = pd.read_csv('y_train.csv')\n",
        "x_N = x_train_df['text'].to_numpy()\n",
        "y_N = y_train_df['is_positive_sentiment'].to_numpy()\n",
        "\n",
        "x_tr_N, x_va_N, y_tr_N, y_va_N = train_test_split(x_N, y_N, test_size=0.2, random_state=42)\n",
        "\n",
        "my_bow_classifier_pipeline = Pipeline([\n",
        "    ('my_bow_feature_extractor', CountVectorizer(stop_words=stop_words, min_df=1, max_df=1.0, ngram_range=(1,1))),\n",
        "    ('my_preproc', PolynomialFeatures(10, include_bias=False)),\n",
        "    ('my_classifier', LogisticRegression(C=1.0, max_iter=100, random_state=101)),\n",
        "])\n",
        "\n",
        "my_parameter_grid_by_name = dict()\n",
        "my_parameter_grid_by_name['my_bow_feature_extractor__min_df'] = [1, 2, 3]\n",
        "my_parameter_grid_by_name['my_preproc__degree'] = [i for i in range(1, 4)]  # underfitting\n",
        "my_parameter_grid_by_name['my_classifier__C'] = np.logspace(0, 6, 10) # overfitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mhSSW-7GVjM",
        "outputId": "24fa6ab6-bab1-44e2-af36-e993b12cad5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold_sizes = [5, 10, 25, 50]\n",
        "data = []\n",
        "\n",
        "best_model = None\n",
        "best_score = None\n",
        "\n",
        "for k in fold_sizes:\n",
        "  grid_searcher = GridSearchCV(\n",
        "      my_bow_classifier_pipeline,\n",
        "      my_parameter_grid_by_name,\n",
        "      scoring='accuracy',\n",
        "      cv=k,\n",
        "      refit=True)\n",
        "\n",
        "  grid_searcher.fit(x_tr_N, y_tr_N)\n",
        "\n",
        "  gsearch_results_df = pd.DataFrame(grid_searcher.cv_results_).copy()\n",
        "  # param_keys = ['param_my_bow_feature_extractor__min_df', 'param_my_classifier__C']\n",
        "  gsearch_results_df.sort_values(['rank_test_score'], inplace=True)\n",
        "\n",
        "  df = gsearch_results_df[['param_my_bow_feature_extractor__min_df', 'param_my_classifier__C', 'split0_test_score', 'rank_test_score']][:10]\n",
        "  df['fold_size'] = len(df['rank_test_score']) * [k]\n",
        "  data.append(df)\n",
        "\n",
        "  if not best_score or best_score < df['split0_test_score'].values[0]:\n",
        "    best_score = df['split0_test_score'].values[0]\n",
        "    best_model = grid_searcher\n",
        "\n",
        "cv_data = pd.concat(data)\n",
        "cv_data.sort_values(['split0_test_score'], inplace=True, ascending=False)\n",
        "cv_data"
      ],
      "metadata": {
        "id": "TUXYM_NAHKRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_va_N = grid_searcher.predict(x_va_N)\n",
        "acc = np.mean(y_va_N == yhat_va_N)\n",
        "\n",
        "print(\"Validation accuracy: %.3f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M9Inr6rJcrI",
        "outputId": "96264899-2fd2-4373-f74f-76852d29e42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pd.read_csv('x_test.csv')\n",
        "x_test_np = x_test['text'].to_numpy()\n",
        "predictions = grid_searcher.predict_proba(x_test_np)\n",
        "\n",
        "for idx, prediction in enumerate(predictions):\n",
        "  # print(prediction, x_test_np[idx])\n",
        "  print(prediction[1])"
      ],
      "metadata": {
        "id": "Lz4oLP87LiV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Solution to Part 2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(set(stopwords.words('english')))\n",
        "\n",
        "x_train_df = pd.read_csv('x_train.csv')\n",
        "y_train_df = pd.read_csv('y_train.csv')\n",
        "x_N = x_train_df['text'].to_numpy()\n",
        "y_N = y_train_df['is_positive_sentiment'].to_numpy()\n",
        "\n",
        "x_tr_N, x_va_N, y_tr_N, y_va_N = train_test_split(x_N, y_N, test_size=0.2, random_state=42)\n",
        "\n",
        "my_bow_classifier_pipeline = Pipeline([\n",
        "    ('my_bow_feature_extractor', CountVectorizer(stop_words=stop_words, min_df=1, max_df=1.0, ngram_range=(1,2))),\n",
        "    ('my_classifier', RandomForestClassifier()),\n",
        "])\n",
        "\n",
        "my_parameter_grid_by_name = dict()\n",
        "my_parameter_grid_by_name['my_bow_feature_extractor__min_df'] = [1, 2, 3]\n",
        "my_parameter_grid_by_name['my_bow_feature_extractor__ngram_range'] = [(1,1), (1,2), (2,2)]\n",
        "my_parameter_grid_by_name['my_classifier__n_estimators'] = [50, 100, 150, 200]\n",
        "my_parameter_grid_by_name['my_classifier__max_depth'] = [2, 4, 8, None] # overfitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJikiYvcExf0",
        "outputId": "0cecbcd7-493d-4d6f-ca55-3fbe6c5c6145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold_sizes = [5, 10, 25, 50]\n",
        "data = []\n",
        "\n",
        "best_model = None\n",
        "best_score = None\n",
        "\n",
        "for k in fold_sizes:\n",
        "  grid_searcher = GridSearchCV(\n",
        "      my_bow_classifier_pipeline,\n",
        "      my_parameter_grid_by_name,\n",
        "      scoring='accuracy',\n",
        "      cv=k,\n",
        "      refit=True)\n",
        "\n",
        "  grid_searcher.fit(x_tr_N, y_tr_N)\n",
        "\n",
        "  gsearch_results_df = pd.DataFrame(grid_searcher.cv_results_).copy()\n",
        "  # param_keys = ['param_my_bow_feature_extractor__min_df', 'param_my_classifier__C']\n",
        "  gsearch_results_df.sort_values(['rank_test_score'], inplace=True)\n",
        "\n",
        "  df = gsearch_results_df[[\n",
        "      'param_my_bow_feature_extractor__min_df',\n",
        "      'param_my_bow_feature_extractor__ngram_range',\n",
        "      'param_my_classifier__n_estimators',\n",
        "      'param_my_classifier__max_depth',\n",
        "      'split0_test_score',\n",
        "      'rank_test_score']][:10]\n",
        "\n",
        "  df['fold_size'] = len(df['rank_test_score']) * [k]\n",
        "  data.append(df)\n",
        "\n",
        "  if not best_score or best_score < df['split0_test_score'].values[0]:\n",
        "    best_score = df['split0_test_score'].values[0]\n",
        "    best_model = grid_searcher\n",
        "\n",
        "cv_data = pd.concat(data)\n",
        "cv_data.sort_values(['split0_test_score'], inplace=True, ascending=False)\n",
        "cv_data"
      ],
      "metadata": {
        "id": "ajGOlheKHnPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_va_N = grid_searcher.predict(x_va_N)\n",
        "acc = np.mean(y_va_N == yhat_va_N)\n",
        "\n",
        "print(\"Validation accuracy: %.3f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxo9a5aCJJFP",
        "outputId": "c26915fc-bed0-44df-f8e6-d7b1bb1aece5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.752\n"
          ]
        }
      ]
    }
  ]
}